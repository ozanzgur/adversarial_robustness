{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import utils, config, trainer, parts\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.nn import functional as F\n",
    "from tools import utils\n",
    "import torch.nn as nn\n",
    "\n",
    "plt.style.use('fast')\n",
    "PLOT_DIR = 'plots'\n",
    "\n",
    "cfg = config.from_yaml(\"experiments\\exp9_net6\\config.yaml\")\n",
    "dataset = utils.load_dataset_module(**cfg.data_supervised)\n",
    "dataset.torch_seed()\n",
    "test_loader = dataset.get_test_loader(**cfg.data_supervised)\n",
    "test_dataset = dataset.get_test_dataset()\n",
    "\n",
    "# Trained model\n",
    "model_trained = utils.load_model(**cfg.model)\n",
    "\n",
    "part_manager_trained = parts.PartManager(model_trained)\n",
    "part_manager_trained.enable_all()\n",
    "\n",
    "i_part = 1\n",
    "trn_trained = trainer.ModelTrainer(model_trained, cfg.trainer_sup, part_manager_trained)\n",
    "model_trained.load_state_dict(torch.load(\"experiments\\exp9_net6\\checkpoint.pth\"))\n",
    "model_trained.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoattack import AutoAttack\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_acc_autoattack(model, device, loader):\n",
    "    correct = 0\n",
    "    n_examples = 0\n",
    "\n",
    "    adversary = AutoAttack(model_trained, norm='Linf', eps=8/255, version='custom', attacks_to_run=['apgd-ce', 'apgd-dlr'])\n",
    "    x_all = []\n",
    "    y_all = []\n",
    "    for x, y in tqdm(loader):\n",
    "        x_all.append(x)\n",
    "        y_all.append(y)\n",
    "        n_examples += x.shape[0]\n",
    "        \n",
    "    x_all = torch.concat(x_all, dim=0).to(device)\n",
    "    y_all = torch.concat(y_all, dim=0).to(device)\n",
    "    \n",
    "    SAMPLE_SIZE = 1000\n",
    "    sample_idx = np.random.choice(len(x_all), SAMPLE_SIZE, replace=False)\n",
    "    x_all = x_all[sample_idx]\n",
    "    y_all = y_all[sample_idx]\n",
    "        \n",
    "    x_all_attack, y_all_attack = adversary.run_standard_evaluation(x_all, y_all, bs=250, return_labels=True)\n",
    "    return x_all_attack, y_all, y_all_attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get samples from each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = 10\n",
    "class_size = 50\n",
    "classes_to_accumulate = list(range(N_CLASSES))\n",
    "examples = {i: [] for i in range(N_CLASSES)}\n",
    "\n",
    "i = 0\n",
    "while True:\n",
    "    x, y = test_dataset[i]\n",
    "    if not y in classes_to_accumulate:\n",
    "        i+=1\n",
    "        continue\n",
    "    \n",
    "    examples[y].append(i)\n",
    "    if len(examples[y]) == class_size:\n",
    "        classes_to_accumulate.remove(y)\n",
    "        if len(classes_to_accumulate) == 0:\n",
    "            break\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_layer = model_trained.se1\n",
    "\n",
    "part_output_trained_list = [[] for _ in range(N_CLASSES)]\n",
    "y_preds = []\n",
    "y_s = []\n",
    "\n",
    "for class_i, class_examples in examples.items():\n",
    "    for example_i in class_examples:\n",
    "        x, y = test_dataset[example_i]\n",
    "        x = x.unsqueeze(0).to(trn_trained.device)\n",
    "        \n",
    "        y_pred = model_trained(x)\n",
    "        y_pred = np.argmax(y_pred.cpu().detach().numpy())\n",
    "        y_s.append(y)\n",
    "        y_preds.append(y_pred)\n",
    "        \n",
    "        part_output_trained = extract_layer.sigmoid_output\n",
    "        part_output_trained = torch.squeeze(part_output_trained).cpu().detach().numpy()\n",
    "        part_output_trained_list[class_i].append(part_output_trained)\n",
    "\n",
    "print(f\"acc: {(np.array(y_preds) == np.array(y_s)).mean()}\")\n",
    "activations_trained = np.array(part_output_trained_list)\n",
    "activations_trained.shape # i_class, i_example, i_kernel, h, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_plot = activations_trained\n",
    "for class_i in range(N_CLASSES):\n",
    "    plt.figure(figsize=(25, 4))\n",
    "    plt.imshow(x_plot[class_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_att, y_att, y_false = get_acc_autoattack(model_trained, trn_trained.device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = 10\n",
    "class_size = 50\n",
    "classes_to_accumulate = list(range(N_CLASSES))\n",
    "examples = {i: [] for i in range(N_CLASSES)}\n",
    "\n",
    "for i in range(len(x_att)):\n",
    "    x, y = x_att[i], y_att[i].cpu().detach().numpy().item()\n",
    "    if not y in classes_to_accumulate:\n",
    "        continue\n",
    "    \n",
    "    examples[y].append(i)\n",
    "    if len(examples[y]) == class_size:\n",
    "        classes_to_accumulate.remove(y)\n",
    "        if len(classes_to_accumulate) == 0:\n",
    "            break\n",
    "\n",
    "extract_layer = model_trained.se1\n",
    "\n",
    "part_output_trained_list = [[] for _ in range(N_CLASSES)]\n",
    "y_preds = []\n",
    "y_s = []\n",
    "\n",
    "for class_i, class_examples in examples.items():\n",
    "    for example_i in class_examples:\n",
    "        x, y = x_att[i], y_att[i].cpu().detach().numpy().item()\n",
    "        x = x.unsqueeze(0).to(trn_trained.device)\n",
    "        \n",
    "        y_pred = model_trained(x)\n",
    "        y_pred = np.argmax(y_pred.cpu().detach().numpy())\n",
    "        y_s.append(y)\n",
    "        y_preds.append(y_pred)\n",
    "        \n",
    "        part_output_trained = extract_layer.sigmoid_output\n",
    "        part_output_trained = torch.squeeze(part_output_trained).cpu().detach().numpy()\n",
    "        part_output_trained_list[class_i].append(part_output_trained)\n",
    "\n",
    "print(f\"acc: {(np.array(y_preds) == np.array(y_s)).mean()}\")\n",
    "activations_trained = np.array(part_output_trained_list)\n",
    "activations_trained.shape # i_class, i_example, i_kernel, h, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_plot = activations_trained\n",
    "for class_i in range(N_CLASSES):\n",
    "    plt.figure(figsize=(25, 5))\n",
    "    plt.imshow(x_plot[class_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8d13dd16ed1d9d0f9b50066a4c58f58f02ea0db6cf3822c9f71a8c066ab69665"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
