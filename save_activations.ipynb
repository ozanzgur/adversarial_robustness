{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import utils, config, trainer, parts\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import functional as F\n",
    "from tools import utils\n",
    "\n",
    "plt.style.use('fast')\n",
    "PLOT_DIR = 'plots'\n",
    "\n",
    "cfg = config.from_yaml(\"experiments\\exp1_cmpe597_regular_mnist\\config.yaml\")\n",
    "\n",
    "dataset = utils.load_dataset_module(**cfg.data_supervised)\n",
    "dataset.torch_seed()\n",
    "test_loader = dataset.get_test_loader(**cfg.data_supervised)\n",
    "test_dataset = dataset.get_test_dataset()\n",
    "\n",
    "# Trained model\n",
    "model = utils.load_model(**cfg.model)\n",
    "model.load_state_dict(torch.load(\"experiments\\exp1_cmpe597_regular_mnist\\checkpoint.pth\"))\n",
    "\n",
    "part_manager = parts.PartManager(model)\n",
    "part_manager.enable_all()\n",
    "\n",
    "trn = trainer.ModelTrainer(model, cfg.trainer_sup, part_manager)\n",
    "\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Adversarial Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attack import do_attack\n",
    "attack_examples = do_attack(model, trn.device, test_loader, fast = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get samples from each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "n_classes = len(classes)\n",
    "class_size = 27\n",
    "classes_to_accumulate = [c for c in classes]\n",
    "examples = {i: [] for i in classes}\n",
    "predictions = {c: [] for c in classes}\n",
    "\n",
    "i = 0\n",
    "while i < len(test_dataset):\n",
    "    x, y = test_dataset[i]\n",
    "    if not y in classes:\n",
    "        i += 1\n",
    "        continue\n",
    "    \n",
    "    if not y in classes_to_accumulate:\n",
    "        i+=1\n",
    "        continue\n",
    "    \n",
    "    x = attack_examples[i]\n",
    "    x = x.unsqueeze(0).to(trn.device)\n",
    "    y_pred = model(x)\n",
    "    y_pred = np.argmax(y_pred.cpu().detach().numpy())\n",
    "    \n",
    "    if y_pred != y:\n",
    "        examples[y].append(i)\n",
    "        predictions[y].append(y_pred)\n",
    "    if len(examples[y]) == class_size:\n",
    "        classes_to_accumulate.remove(y)\n",
    "        if len(classes_to_accumulate) == 0:\n",
    "            break\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of perturbed examples per class:\")\n",
    "[f'{k}:{len(v)}' for k, v in examples.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Outputs for Adversarial and Regular Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_i = 0\n",
    "\n",
    "part_output_list_adv = [[] for _ in range(n_classes)]\n",
    "part_output_list = [[] for _ in range(n_classes)]\n",
    "\n",
    "for class_i, class_examples in examples.items():\n",
    "    class_order = classes.index(class_i)\n",
    "    for example_i in class_examples:\n",
    "        x, y = test_dataset[example_i]\n",
    "        x = x.unsqueeze(0).to(trn.device)\n",
    "        _ = model(x)\n",
    "        \n",
    "        part_output = getattr(part_manager.parts[part_i].get_loss_end_layer(), trainer.SAVED_OUTPUT_NAME)\n",
    "        part_output = torch.squeeze(part_output).cpu().detach().numpy()\n",
    "        part_output_list[class_order].append(part_output)\n",
    "        \n",
    "        x = attack_examples[example_i]\n",
    "        x = x.unsqueeze(0).to(trn.device)\n",
    "        _ = model(x)\n",
    "        \n",
    "        part_output = getattr(part_manager.parts[part_i].get_loss_end_layer(), trainer.SAVED_OUTPUT_NAME)\n",
    "        part_output = torch.squeeze(part_output).cpu().detach().numpy()\n",
    "        part_output_list_adv[class_order].append(part_output)\n",
    "    \n",
    "activations = np.array(part_output_list)\n",
    "activations_adv = np.array(part_output_list_adv)\n",
    "\n",
    "activations.shape # i_class, i_example, i_kernel, h, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flattened_activations(activations, class_i, channel_i):\n",
    "    flat_size = class_size\n",
    "    h = activations.shape[-2]\n",
    "\n",
    "    flattened_kernel = np.zeros((h, flat_size * h))\n",
    "    for example_i in range(activations.shape[1]):\n",
    "        flattened_kernel[:, example_i * h: (example_i+1) * h] = activations[class_i, example_i, channel_i]\n",
    "    return flattened_kernel\n",
    "\n",
    "class_i = 0\n",
    "channel_i = 0\n",
    "flattened_activations = get_flattened_activations(activations, class_i, channel_i)\n",
    "flattened_activations_adv = get_flattened_activations(activations_adv, class_i, channel_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flattened activations for a single kernel - Regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 5))\n",
    "plt.imshow(flattened_activations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flattened activations for a single kernel - Adversarial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 5))\n",
    "plt.imshow(flattened_activations_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KERNEL_I = 1\n",
    "for class_i in range(n_classes):\n",
    "    plt.figure(figsize=(30, 3))\n",
    "    flat_kernel = get_flattened_activations(activations, class_i, KERNEL_I)\n",
    "    plt.imshow(flat_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_i in range(n_classes):\n",
    "    plt.figure(figsize=(30, 5))\n",
    "    flat_kernel = get_flattened_activations(activations_adv, class_i, KERNEL_I)\n",
    "    plt.imshow(flat_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations_median = np.mean(activations, axis=1).reshape((10, -1))\n",
    "activations_adv_median = np.mean(activations_adv, axis=1).reshape((10, -1))\n",
    "\n",
    "activations_median_std = np.nan_to_num(activations_median.std(axis=0))\n",
    "activations_adv_median_std = np.nan_to_num(activations_adv_median.std(axis=0), nan=1.0)\n",
    "activations_median_std[activations_median_std==0] = 1.0\n",
    "activations_adv_median_std[activations_adv_median_std==0] = 1.0\n",
    "\n",
    "activations_median = (activations_median - activations_median.mean(axis=0)) / activations_median_std\n",
    "activations_adv_median = (activations_adv_median - activations_adv_median.mean(axis=0)) / activations_adv_median_std\n",
    "\n",
    "\"\"\"activations_median = np.nan_to_num(activations_median, nan=np.nanmin(activations_median))\n",
    "activations_adv_median = np.nan_to_num(activations_adv_median, nan=np.nanmin(activations_adv_median))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_i = 8\n",
    "activations_median_copy = activations_median.copy()\n",
    "activations_median_copy[exclude_i] = 0\n",
    "max_activations = np.max(activations_median_copy, axis=0)\n",
    "activations_median_copy[exclude_i] = 999\n",
    "min_activations = np.min(activations_median_copy, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_class_most_activated = activations_median[exclude_i] - max_activations > 0\n",
    "excluded_class_least_activated = activations_median[exclude_i] - min_activations < 0\n",
    "excluded_feature_selected = np.logical_or(excluded_class_most_activated, excluded_class_least_activated)\n",
    "diff_order = np.argsort(activations_median[exclude_i])\n",
    "\n",
    "print(f\"Excluded class is least activated in these features: {excluded_class_least_activated.sum()}\")\n",
    "print(f\"Excluded class is most activated in these features: {excluded_class_most_activated.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(35, 5))\n",
    "plt.imshow(activations_median[:, diff_order][:, -200:])\n",
    "\n",
    "plt.figure(figsize=(35, 5))\n",
    "plt.imshow(activations_adv_median[:, diff_order][:, -200:])\n",
    "print(\"Activations sorted by their values for y=8 on regular examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(35, 5))\n",
    "act = activations_median[:, excluded_feature_selected]\n",
    "act_order = np.argsort(act[exclude_i, :])\n",
    "plt.imshow(act[:, act_order])\n",
    "\n",
    "plt.figure(figsize=(35, 5))\n",
    "act_adv = activations_adv_median[:, excluded_feature_selected]\n",
    "plt.imshow(act_adv[: , act_order])\n",
    "print(\"Activations where value for y=8 is the min or max among classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = activations_median.shape[1]\n",
    "robustness = np.zeros(n_features)\n",
    "usefulness = np.zeros(n_features)\n",
    "for i in range(n_features):\n",
    "    usefulness[i] = (activations_median[:, i].max() - activations_median[:, i].mean()) / activations_median[:, i].std()\n",
    "    robustness[i] = np.corrcoef(activations_median[:, i], activations_adv_median[:, i])[0, 1]\n",
    "        \n",
    "robustness = np.nan_to_num(robustness)\n",
    "usefulness = np.nan_to_num(usefulness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_order = np.argsort(usefulness)\n",
    "plt.figure(figsize=(35, 7))\n",
    "plt.imshow(activations_median[:, feature_order][:, -150:])\n",
    "plt.title(\"Activations for regular examples\")\n",
    "\n",
    "plt.figure(figsize=(35, 7))\n",
    "plt.imshow(activations_adv_median[:, feature_order][:, -150:])\n",
    "plt.title(\"Activations for adversarial examples\")\n",
    "print(\"Features sorted by usefulness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_order = np.argsort(robustness)\n",
    "robustness_sorted = np.sort(robustness)\n",
    "plt.figure(figsize=(35, 7))\n",
    "plt.imshow(activations_median[:, feature_order][:, -75:])\n",
    "plt.title(\"Activations for regular examples (top 75)\")\n",
    "\n",
    "plt.figure(figsize=(35, 7))\n",
    "plt.imshow(activations_adv_median[:, feature_order][:, -75:])\n",
    "plt.title(\"Activations for adversarial examples (top 75)\")\n",
    "\n",
    "plt.figure(figsize=(35, 7))\n",
    "plt.imshow(activations_median[:, feature_order][:, :75])\n",
    "plt.title(\"Activations for regular examples (bottom 75)\")\n",
    "\n",
    "plt.figure(figsize=(35, 7))\n",
    "plt.imshow(activations_adv_median[:, feature_order][:, :75])\n",
    "plt.title(\"Activations for adversarial examples (bottom 75)\")\n",
    "print(\"Features sorted by robustness\")\n",
    "print(f\"Top 25: {list(reversed(robustness_sorted[-25:]))}\")\n",
    "print(f\"Bottom 25: {robustness_sorted[:25]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(usefulness, robustness)\n",
    "plt.xlim([1.0, 3.1])\n",
    "plt.xlabel(\"usefulness\")\n",
    "plt.ylabel(\"robustness\")\n",
    "print(f\"Correlation: {np.corrcoef(usefulness, robustness)[1, 0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robustness for kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_robustness = robustness.reshape((20, 7, 7)).mean(axis=(1,2))\n",
    "kernel_usefulness = usefulness.reshape((20, 7, 7)).mean(axis=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.argsort(kernel_robustness):\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.imshow(model.conv1.weight[i, 0].cpu().detach().numpy(), cmap=\"gray\")\n",
    "    plt.title(f\"{i}: robustness={kernel_robustness[i]:.3f}, usefulness={kernel_usefulness[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(kernel_usefulness, kernel_robustness)\n",
    "plt.xlabel(\"kernel_usefulness\")\n",
    "plt.ylabel(\"kernel_robustness\")\n",
    "print(f\"Correlation: {np.corrcoef(kernel_usefulness, kernel_robustness)[1, 0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels_to_zero = np.argsort(kernel_robustness)[:2]\n",
    "new_w = model.conv1.weight.clone()\n",
    "new_b = model.conv1.bias.clone()\n",
    "\n",
    "for i_kernel in kernels_to_zero:\n",
    "    new_w[i_kernel] = 0.0\n",
    "    new_b[i_kernel] = -100000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.conv1.weight = torch.nn.Parameter(new_w)\n",
    "model.conv1.bias = torch.nn.Parameter(new_b)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attack import do_attack\n",
    "attack_examples = do_attack(model, trn.device, test_loader, fast = False, first_n = 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featrues_to_zero = np.argsort(usefulness)[:10]\n",
    "feature_mask = np.ones(activations.shape[2] * activations.shape[3] * activations.shape[4])\n",
    "feature_mask[featrues_to_zero] = 0.0\n",
    "\n",
    "feature_mask = feature_mask.reshape((1, activations.shape[2], activations.shape[3], activations.shape[4]))\n",
    "model.feature_gate = torch.nn.Parameter(torch.tensor(feature_mask, dtype=torch.float32).cuda())\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attack import do_attack\n",
    "attack_examples = do_attack(model, trn.device, test_loader, fast = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('adv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4c65ffda61ca68038c05c26603533cf56bcab691d385cb6a8da63f9628db81c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
